{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec28821f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://nexus3.sqcorp.co/repository/pypi-all/simple\n",
      "Collecting torch-geometric\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/torch-geometric/2.0.2/torch_geometric-2.0.2.tar.gz (325 kB)\n",
      "\u001b[K     |████████████████████████████████| 325 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/numpy/1.21.4/numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.7 MB 84.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/tqdm/4.62.3/tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 79.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/scipy/1.7.3/scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 38.1 MB 85.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/networkx/2.6.3/networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 82.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/scikit-learn/1.0.1/scikit_learn-1.0.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.2 MB 83.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/requests/2.26.0/requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 33.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/pandas/1.3.4/pandas-1.3.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 72.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rdflib\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/rdflib/6.0.2/rdflib-6.0.2-py3-none-any.whl (407 kB)\n",
      "\u001b[K     |████████████████████████████████| 407 kB 101.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting googledrivedownloader\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/googledrivedownloader/0.4/googledrivedownloader-0.4-py2.py3-none-any.whl (3.9 kB)\n",
      "Collecting jinja2\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/jinja2/3.0.3/Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 105.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/pyparsing/3.0.6/pyparsing-3.0.6-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 109.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting yacs\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/yacs/0.1.8/yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Collecting PyYAML\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/pyyaml/6.0/PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 92.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/markupsafe/2.0.1/MarkupSafe-2.0.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (31 kB)\n",
      "Collecting pytz>=2017.3\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/pytz/2021.3/pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
      "\u001b[K     |████████████████████████████████| 503 kB 90.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dateutil>=2.7.3\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/python-dateutil/2.8.2/python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "\u001b[K     |████████████████████████████████| 247 kB 87.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.5\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/six/1.16.0/six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting setuptools\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/setuptools/59.4.0/setuptools-59.4.0-py3-none-any.whl (952 kB)\n",
      "\u001b[K     |████████████████████████████████| 952 kB 70.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting isodate\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/isodate/0.6.0/isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 63.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/idna/3.3/idna-3.3-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 69.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/certifi/2021.10.8/certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
      "\u001b[K     |████████████████████████████████| 149 kB 76.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer~=2.0.0\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/charset-normalizer/2.0.8/charset_normalizer-2.0.8-py3-none-any.whl (39 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/urllib3/1.26.7/urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 121.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/joblib/1.1.0/joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[K     |████████████████████████████████| 306 kB 109.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading https://nexus3.sqcorp.co/repository/pypi-all/packages/threadpoolctl/3.0.0/threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: torch-geometric\n",
      "  Building wheel for torch-geometric (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch-geometric: filename=torch_geometric-2.0.2-py3-none-any.whl size=535569 sha256=0314507d1bc8e61858eec60dab8deee1cd296142072f46c941cb5a952db4aa25\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sw_dktm5/wheels/ef/52/7f/cd21311e87da9d2d1f696654b6d28da46365375b94373a2444\n",
      "Successfully built torch-geometric\n",
      "Installing collected packages: six, numpy, urllib3, threadpoolctl, setuptools, scipy, PyYAML, pytz, python-dateutil, pyparsing, MarkupSafe, joblib, isodate, idna, charset-normalizer, certifi, yacs, tqdm, scikit-learn, requests, rdflib, pandas, networkx, jinja2, googledrivedownloader, torch-geometric\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.25.11\n",
      "    Uninstalling urllib3-1.25.11:\n",
      "      Successfully uninstalled urllib3-1.25.11\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 2.2.0\n",
      "    Uninstalling threadpoolctl-2.2.0:\n",
      "      Successfully uninstalled threadpoolctl-2.2.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 57.4.0\n",
      "    Uninstalling setuptools-57.4.0:\n",
      "      Successfully uninstalled setuptools-57.4.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.7.1\n",
      "    Uninstalling scipy-1.7.1:\n",
      "      Successfully uninstalled scipy-1.7.1\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2021.1\n",
      "    Uninstalling pytz-2021.1:\n",
      "      Successfully uninstalled pytz-2021.1\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.2\n",
      "    Uninstalling python-dateutil-2.8.2:\n",
      "      Successfully uninstalled python-dateutil-2.8.2\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 2.4.7\n",
      "    Uninstalling pyparsing-2.4.7:\n",
      "      Successfully uninstalled pyparsing-2.4.7\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.0.1\n",
      "    Uninstalling MarkupSafe-2.0.1:\n",
      "      Successfully uninstalled MarkupSafe-2.0.1\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.0.1\n",
      "    Uninstalling joblib-1.0.1:\n",
      "      Successfully uninstalled joblib-1.0.1\n",
      "  Attempting uninstall: isodate\n",
      "    Found existing installation: isodate 0.6.0\n",
      "    Uninstalling isodate-0.6.0:\n",
      "      Successfully uninstalled isodate-0.6.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 2.10\n",
      "    Uninstalling idna-2.10:\n",
      "      Successfully uninstalled idna-2.10\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.0.4\n",
      "    Uninstalling charset-normalizer-2.0.4:\n",
      "      Successfully uninstalled charset-normalizer-2.0.4\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2021.5.30\n",
      "    Uninstalling certifi-2021.5.30:\n",
      "      Successfully uninstalled certifi-2021.5.30\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.62.1\n",
      "    Uninstalling tqdm-4.62.1:\n",
      "      Successfully uninstalled tqdm-4.62.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.2\n",
      "    Uninstalling scikit-learn-0.24.2:\n",
      "      Successfully uninstalled scikit-learn-0.24.2\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.23.0\n",
      "    Uninstalling requests-2.23.0:\n",
      "      Successfully uninstalled requests-2.23.0\n",
      "  Attempting uninstall: rdflib\n",
      "    Found existing installation: rdflib 6.0.0\n",
      "    Uninstalling rdflib-6.0.0:\n",
      "      Successfully uninstalled rdflib-6.0.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.0\n",
      "    Uninstalling pandas-1.3.0:\n",
      "      Successfully uninstalled pandas-1.3.0\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 2.6.2\n",
      "    Uninstalling networkx-2.6.2:\n",
      "      Successfully uninstalled networkx-2.6.2\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.0.1\n",
      "    Uninstalling Jinja2-3.0.1:\n",
      "      Successfully uninstalled Jinja2-3.0.1\n",
      "  Attempting uninstall: googledrivedownloader\n",
      "    Found existing installation: googledrivedownloader 0.4\n",
      "    Uninstalling googledrivedownloader-0.4:\n",
      "      Successfully uninstalled googledrivedownloader-0.4\n",
      "  Attempting uninstall: torch-geometric\n",
      "    Found existing installation: torch-geometric 1.7.2\n",
      "    Uninstalling torch-geometric-1.7.2:\n",
      "      Successfully uninstalled torch-geometric-1.7.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.5.0 requires numpy~=1.19.2, but you have numpy 1.21.4 which is incompatible.\n",
      "tensorflow 2.5.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
      "prefect 0.14.22 requires click<8.0,>=7.0, but you have click 8.0.1 which is incompatible.\n",
      "httplib2 0.19.1 requires pyparsing<3,>=2.4.2, but you have pyparsing 3.0.6 which is incompatible.\n",
      "botocore 1.17.63 requires urllib3<1.26,>=1.20; python_version != \"3.4\", but you have urllib3 1.26.7 which is incompatible.\u001b[0m\n",
      "Successfully installed MarkupSafe-2.0.1 PyYAML-6.0 certifi-2021.10.8 charset-normalizer-2.0.8 googledrivedownloader-0.4 idna-3.3 isodate-0.6.0 jinja2-3.0.3 joblib-1.1.0 networkx-2.6.3 numpy-1.21.4 pandas-1.3.4 pyparsing-3.0.6 python-dateutil-2.8.2 pytz-2021.3 rdflib-6.0.2 requests-2.26.0 scikit-learn-1.0.1 scipy-1.7.3 setuptools-59.4.0 six-1.16.0 threadpoolctl-3.0.0 torch-geometric-2.0.2 tqdm-4.62.3 urllib3-1.26.7 yacs-0.1.8\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e520d122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n",
      "1.9.0+cu111\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric\n",
    "print(torch_geometric.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26ac6617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'edge_index': tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
      "        [ 633, 1862, 2582,  ...,  598, 1473, 2706]], device='cuda:0'), 'y': tensor([3, 4, 4,  ..., 3, 3, 3], device='cuda:0'), 'train_mask': tensor([ True,  True,  True,  ..., False, False, False], device='cuda:0'), 'val_mask': tensor([False, False, False,  ..., False, False, False], device='cuda:0'), 'test_mask': tensor([False, False, False,  ...,  True,  True,  True], device='cuda:0')}\n",
      "['val_mask', 'test_mask', 'edge_index', 'train_mask', 'x', 'y']\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking arugment for argument tensors in method wrapper__cat)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_72/414574324.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomLinkSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_undirected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/transforms/random_link_split.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mtrain_edges\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mneg_edge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_neg_val\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_neg_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_store\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             )\n\u001b[1;32m    208\u001b[0m             self._create_label(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/transforms/random_link_split.py\u001b[0m in \u001b[0;36m_create_label\u001b[0;34m(self, store, index, neg_edge_index, out)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mneg_edge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0medge_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_edge_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                 \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_edge_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{self.key}_index'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking arugment for argument tensors in method wrapper__cat)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "])\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Planetoid', name='Cora', transform=transform)\n",
    "\n",
    "data = dataset[0]\n",
    "print(data.to_dict())\n",
    "print(data.keys)\n",
    "\n",
    "transform = T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,)\n",
    "train_data, val_data, test_data = transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e321800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "\n",
    "model = Net(dataset.num_features, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fc5b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffbb1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f60a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "z = model.encode(test_data.x, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd88e122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
